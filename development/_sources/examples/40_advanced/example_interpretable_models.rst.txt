
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_interpretable_models.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_interpretable_models.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_interpretable_models.py:


====================
Interpretable models
====================

The following example shows how to inspect the models which *auto-sklearn*
optimizes over and how to restrict them to an interpretable subset.

.. GENERATED FROM PYTHON SOURCE LINES 10-15

.. code-block:: default

    import autosklearn.classification
    import autosklearn.pipeline.components.classification
    import sklearn.datasets
    import sklearn.metrics








.. GENERATED FROM PYTHON SOURCE LINES 16-22

Show available classification models
====================================

We will first list all classifiers Auto-sklearn chooses from. A similar
call is available for preprocessors (see below) and regression (not shown)
as well.

.. GENERATED FROM PYTHON SOURCE LINES 22-25

.. code-block:: default

    for name in autosklearn.pipeline.components.classification.ClassifierChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    adaboost
    bernoulli_nb
    decision_tree
    extra_trees
    gaussian_nb
    gradient_boosting
    k_nearest_neighbors
    lda
    liblinear_svc
    libsvm_svc
    mlp
    multinomial_nb
    passive_aggressive
    qda
    random_forest
    sgd




.. GENERATED FROM PYTHON SOURCE LINES 26-28

Show available preprocessors
============================

.. GENERATED FROM PYTHON SOURCE LINES 28-34

.. code-block:: default


    import autosklearn.pipeline.components.feature_preprocessing

    for name in autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    densifier
    extra_trees_preproc_for_classification
    extra_trees_preproc_for_regression
    fast_ica
    feature_agglomeration
    kernel_pca
    kitchen_sinks
    liblinear_svc_preprocessor
    no_preprocessing
    nystroem_sampler
    pca
    polynomial
    random_trees_embedding
    select_percentile_classification
    select_percentile_regression
    select_rates_classification
    select_rates_regression
    truncatedSVD




.. GENERATED FROM PYTHON SOURCE LINES 35-37

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 37-42

.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








.. GENERATED FROM PYTHON SOURCE LINES 43-51

Build and fit a classifier
==========================

We will now only use a subset of the given classifiers and preprocessors.
Furthermore, we will restrict the ensemble size to ``1`` to only use the
single best model in the end. However, we would like to note that the
choice of which models is deemed interpretable is very much up to the user
and can change from use case to use case.

.. GENERATED FROM PYTHON SOURCE LINES 51-62

.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp',
        include={'classifier': ['decision_tree', 'lda', 'sgd'],
                 'feature_preprocessor': ['no_preprocessing', 'polynomial', 'select_percentile_classification']},
        ensemble_size=1,
    )
    automl.fit(X_train, y_train, dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(ensemble_size=1,
                          include={'classifier': ['decision_tree', 'lda', 'sgd'],
                                   'feature_preprocessor': ['no_preprocessing',
                                                            'polynomial',
                                                            'select_percentile_classification']},
                          per_run_time_limit=30, time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp')



.. GENERATED FROM PYTHON SOURCE LINES 63-65

Print the final ensemble constructed by auto-sklearn
====================================================

.. GENERATED FROM PYTHON SOURCE LINES 65-68

.. code-block:: default


    print(automl.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'sgd', 'data_preprocessor:__choice__': 'feature_type', 'feature_preprocessor:__choice__': 'polynomial', 'classifier:sgd:alpha': 0.0003194044719261622, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'invscaling', 'classifier:sgd:loss': 'log', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 3.224657440425691e-05, 'data_preprocessor:feature_type:categorical_transformer:categorical_encoding:__choice__': 'encoding', 'data_preprocessor:feature_type:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessor:feature_type:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessor:feature_type:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'False', 'feature_preprocessor:polynomial:interaction_only': 'True', 'classifier:sgd:eta0': 0.005855617194547085, 'classifier:sgd:power_t': 0.5, 'data_preprocessor:feature_type:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.36245512200942104},
    dataset_properties={
      'task': 1,
      'sparse': False,
      'multilabel': False,
      'multiclass': False,
      'target_type': 'classification',
      'signed': False})),
    ]




.. GENERATED FROM PYTHON SOURCE LINES 69-71

Get the Score of the final ensemble
===================================

.. GENERATED FROM PYTHON SOURCE LINES 71-74

.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:", sklearn.metrics.accuracy_score(y_test, predictions))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score: 0.951048951048951





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  56.977 seconds)


.. _sphx_glr_download_examples_40_advanced_example_interpretable_models.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/40_advanced/example_interpretable_models.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_interpretable_models.py <example_interpretable_models.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_interpretable_models.ipynb <example_interpretable_models.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
