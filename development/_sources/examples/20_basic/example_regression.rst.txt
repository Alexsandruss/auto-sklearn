
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/20_basic/example_regression.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_20_basic_example_regression.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_20_basic_example_regression.py:


==========
Regression
==========

The following example shows how to fit a simple regression model with
*auto-sklearn*.

.. GENERATED FROM PYTHON SOURCE LINES 10-16

.. code-block:: default

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.regression
    import matplotlib.pyplot as plt








.. GENERATED FROM PYTHON SOURCE LINES 17-19

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 19-25

.. code-block:: default


    X, y = sklearn.datasets.load_diabetes(return_X_y=True)

    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








.. GENERATED FROM PYTHON SOURCE LINES 26-28

Build and fit a regressor
=========================

.. GENERATED FROM PYTHON SOURCE LINES 28-36

.. code-block:: default


    automl = autosklearn.regression.AutoSklearnRegressor(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_regression_example_tmp',
    )
    automl.fit(X_train, y_train, dataset_name='diabetes')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnRegressor(per_run_time_limit=30, time_left_for_this_task=120,
                         tmp_folder='/tmp/autosklearn_regression_example_tmp')



.. GENERATED FROM PYTHON SOURCE LINES 37-39

Print the final ensemble constructed by auto-sklearn
====================================================

.. GENERATED FROM PYTHON SOURCE LINES 39-42

.. code-block:: default


    print(automl.show_models())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [(0.340000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'polynomial', 'regressor:__choice__': 'ard_regression', 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'True', 'feature_preprocessor:polynomial:interaction_only': 'False', 'regressor:ard_regression:alpha_1': 0.0003701926442639788, 'regressor:ard_regression:alpha_2': 2.2118001735899097e-07, 'regressor:ard_regression:fit_intercept': 'True', 'regressor:ard_regression:lambda_1': 1.2037591637980971e-06, 'regressor:ard_regression:lambda_2': 4.358378124977852e-09, 'regressor:ard_regression:n_iter': 300, 'regressor:ard_regression:threshold_lambda': 1136.5286041327277, 'regressor:ard_regression:tol': 0.021944240404849075},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.280000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'polynomial', 'regressor:__choice__': 'gaussian_process', 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1044, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'feature_preprocessor:polynomial:degree': 2, 'feature_preprocessor:polynomial:include_bias': 'True', 'feature_preprocessor:polynomial:interaction_only': 'True', 'regressor:gaussian_process:alpha': 0.40377128710801274, 'regressor:gaussian_process:thetaL': 0.0006440074254633847, 'regressor:gaussian_process:thetaU': 18.039349882600167},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.180000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'polynomial', 'regressor:__choice__': 'sgd', 'feature_preprocessor:polynomial:degree': 3, 'feature_preprocessor:polynomial:include_bias': 'False', 'feature_preprocessor:polynomial:interaction_only': 'False', 'regressor:sgd:alpha': 0.0006517033225329654, 'regressor:sgd:average': 'False', 'regressor:sgd:fit_intercept': 'True', 'regressor:sgd:learning_rate': 'invscaling', 'regressor:sgd:loss': 'epsilon_insensitive', 'regressor:sgd:penalty': 'elasticnet', 'regressor:sgd:tol': 0.002431731981071206, 'regressor:sgd:epsilon': 0.012150149892783745, 'regressor:sgd:eta0': 0.016444224834275295, 'regressor:sgd:l1_ratio': 1.7462342366289323e-09, 'regressor:sgd:power_t': 0.21521743568582094},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.140000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'select_rates_regression', 'regressor:__choice__': 'liblinear_svr', 'feature_preprocessor:select_rates_regression:alpha': 0.034904198000955684, 'feature_preprocessor:select_rates_regression:mode': 'fdr', 'feature_preprocessor:select_rates_regression:score_func': 'f_regression', 'regressor:liblinear_svr:C': 35.012615180923554, 'regressor:liblinear_svr:dual': 'False', 'regressor:liblinear_svr:epsilon': 0.7326132441316412, 'regressor:liblinear_svr:fit_intercept': 'True', 'regressor:liblinear_svr:intercept_scaling': 1, 'regressor:liblinear_svr:loss': 'squared_epsilon_insensitive', 'regressor:liblinear_svr:tol': 0.00012982617662684841},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.020000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'gaussian_process', 'feature_preprocessor:feature_agglomeration:affinity': 'cosine', 'feature_preprocessor:feature_agglomeration:linkage': 'average', 'feature_preprocessor:feature_agglomeration:n_clusters': 88, 'feature_preprocessor:feature_agglomeration:pooling_func': 'median', 'regressor:gaussian_process:alpha': 0.42928092501196696, 'regressor:gaussian_process:thetaL': 6.172116627632286e-09, 'regressor:gaussian_process:thetaU': 16.276500613703412},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.020000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'libsvm_svr', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014192135928954746, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'exp', 'feature_preprocessor:fast_ica:whiten': 'False', 'regressor:libsvm_svr:C': 1.4272136443763257, 'regressor:libsvm_svr:epsilon': 0.10000000000000006, 'regressor:libsvm_svr:kernel': 'poly', 'regressor:libsvm_svr:max_iter': -1, 'regressor:libsvm_svr:shrinking': 'False', 'regressor:libsvm_svr:tol': 0.0010000000000000002, 'regressor:libsvm_svr:coef0': 0.2694141260648879, 'regressor:libsvm_svr:degree': 2, 'regressor:libsvm_svr:gamma': 0.05757315877344016},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.020000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'select_rates_regression', 'regressor:__choice__': 'ard_regression', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0001745391328519669, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.8057830372269097, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.24982831110057324, 'feature_preprocessor:select_rates_regression:alpha': 0.3621762718897781, 'feature_preprocessor:select_rates_regression:mode': 'fwe', 'feature_preprocessor:select_rates_regression:score_func': 'f_regression', 'regressor:ard_regression:alpha_1': 2.7664515192592053e-05, 'regressor:ard_regression:alpha_2': 9.504988116581138e-07, 'regressor:ard_regression:fit_intercept': 'True', 'regressor:ard_regression:lambda_1': 6.50650698230178e-09, 'regressor:ard_regression:lambda_2': 4.238533890074848e-07, 'regressor:ard_regression:n_iter': 300, 'regressor:ard_regression:threshold_lambda': 78251.58542976103, 'regressor:ard_regression:tol': 0.0007301343236220855},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    ]




.. GENERATED FROM PYTHON SOURCE LINES 43-49

Get the Score of the final ensemble
===================================
After training the estimator, we can now quantify the goodness of fit. One possibility for
is the `R2 score <https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score>`_.
The values range between -inf and 1 with 1 being the best possible value. A dummy estimator
predicting the data mean has an R2 score of 0.

.. GENERATED FROM PYTHON SOURCE LINES 49-55

.. code-block:: default


    train_predictions = automl.predict(X_train)
    print("Train R2 score:", sklearn.metrics.r2_score(y_train, train_predictions))
    test_predictions = automl.predict(X_test)
    print("Test R2 score:", sklearn.metrics.r2_score(y_test, test_predictions))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Train R2 score: 0.6002847747478639
    Test R2 score: 0.37665063814768507




.. GENERATED FROM PYTHON SOURCE LINES 56-63

Plot the predictions
====================
Furthermore, we can now visually inspect the predictions. We plot the true value against the
predictions and show results on train and test data. Points on the diagonal depict perfect
predictions. Points below the diagonal were overestimated by the model (predicted value is higher
than the true value), points above the diagonal were underestimated (predicted value is lower than
the true value).

.. GENERATED FROM PYTHON SOURCE LINES 63-74

.. code-block:: default


    plt.scatter(train_predictions, y_train, label="Train samples", c='#d95f02')
    plt.scatter(test_predictions, y_test, label="Test samples", c='#7570b3')
    plt.xlabel("Predicted value")
    plt.ylabel("True value")
    plt.legend()
    plt.plot([30, 400], [30, 400], c='k', zorder=0)
    plt.xlim([30, 400])
    plt.ylim([30, 400])
    plt.tight_layout()
    plt.show()



.. image:: /examples/20_basic/images/sphx_glr_example_regression_001.png
    :alt: example regression
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  59.099 seconds)


.. _sphx_glr_download_examples_20_basic_example_regression.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/20_basic/example_regression.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_regression.py <example_regression.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_regression.ipynb <example_regression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
